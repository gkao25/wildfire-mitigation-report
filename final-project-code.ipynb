{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint 1 Code\n",
    "\n",
    "By: Gloria Kao, Shentong Li\n",
    "\n",
    "Outputs (tables, aggregated data, graphs, etc.) are commented out and not shown because of NDA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "# pacakges for geospatial analysis and plotting\n",
    "import geopandas as gpd\n",
    "import folium\n",
    "import seaborn as sns\n",
    "from shapely.geometry import Point\n",
    "import matplotlib.pyplot as plt\n",
    "from folium.plugins import HeatMap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 5 datasets in total. We focus on 3 of them first: \n",
    "\n",
    "1. `gis_weatherstation_shape_2024_10_04.csv`: Information of weather stations such as names, location, structure details, etc.\n",
    "2. `src_wings_meteorology_station_summary_snapshot_2023_08_02.csv`: Meteorology data for each weather stations such as max gust and alert windspeed. \n",
    "3. `src_wings_meteorology_windspeed_snapshot_2023_08_02.csv`: Windspeed snapshots collected from weather stations, ranging from years 2012 to 2022. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gis_2024_1004 = pd.read_csv('data/gis_weatherstation_shape_2024_10_04.csv')\n",
    "station_summary_2023_08_02 = pd.read_csv('data/src_wings_meteorology_station_summary_snapshot_2023_08_02.csv')\n",
    "windspeed_2023_08_02 = pd.read_csv('data/src_wings_meteorology_windspeed_snapshot_2023_08_02.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Table 1 - GIS 2024_10_04\n",
    "#### 1.1.1 Basic Summary Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gis_2024_1004"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gis_2024_1004.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_location = gis_2024_1004[['weatherstationcode', 'latitude', 'longitude']]\n",
    "station_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gis_2024_1004.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check null\n",
    "gis_2024_1004.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num of stations contained\n",
    "gis_2024_1004['weatherstationname'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_stations = gis_2024_1004[gis_2024_1004.duplicated(subset=['weatherstationname'], keep=False)]\n",
    "duplicate_stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count of each values in 'nwszone'\n",
    "gis_2024_1004['nwszone'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.2 Geospatial Analysis\n",
    "Show the details of each station by clicking on the icon in the map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_center = [gis_2024_1004['latitude'].mean(), gis_2024_1004['longitude'].mean()]\n",
    "m1 = folium.Map(location=map_center, zoom_start=10)\n",
    "\n",
    "# Add weather station points to the map\n",
    "for _, row in gis_2024_1004.iterrows():\n",
    "    # Create a popup with relevant information\n",
    "    popup_text = f\"\"\"\n",
    "    Weather Station: {row['weatherstationname']}<br>\n",
    "    Elevation: {row['elevation']} m<br>\n",
    "    NWS Zone: {row['nwszone']}<br>\n",
    "    Structure ID: {row['structureid']}<br>\n",
    "    \"\"\"\n",
    "    \n",
    "    # Add a marker for each weather station\n",
    "    folium.Marker(\n",
    "        location=[row['latitude'], row['longitude']],\n",
    "        popup=folium.Popup(popup_text, max_width=300),\n",
    "        icon=folium.Icon(color='blue', icon='info-sign')\n",
    "    ).add_to(m1)\n",
    "\n",
    "\n",
    "boundary_coords = [\n",
    "    (gis_2024_1004['latitude'].min(), gis_2024_1004['longitude'].min()),\n",
    "    (gis_2024_1004['latitude'].min(), gis_2024_1004['longitude'].max()),\n",
    "    (gis_2024_1004['latitude'].max(), gis_2024_1004['longitude'].max()),\n",
    "    (gis_2024_1004['latitude'].max(), gis_2024_1004['longitude'].min())\n",
    "]\n",
    "\n",
    "# boundary box\n",
    "# folium.Polygon(locations=boundary_coords, color='green', fill=True, fill_opacity=0.2).add_to(m1)\n",
    "\n",
    "m1.save('weather_stations_with_area_map.html')\n",
    "m1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Table 2 - Station Summary 2023_08_02\n",
    "#### 1.2.1 Basic Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_summary_2023_08_02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_summary_2023_08_02.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution graphs \n",
    "sns.histplot(station_summary_2023_08_02['max_gust'], bins=10, kde=True)\n",
    "plt.title('Distribution of Maximum Gusts')\n",
    "plt.xlabel('Max Gust (mph)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "# plt.close()\n",
    "\n",
    "\n",
    "sns.histplot(station_summary_2023_08_02['99th'], bins=10, kde=True)\n",
    "plt.title('Distribution of 99th Percentile Gusts')\n",
    "plt.xlabel('99th Percentile Gust (mph)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "# plt.close()\n",
    "\n",
    "\n",
    "sns.histplot(station_summary_2023_08_02['95th'], bins=10, kde=True)\n",
    "plt.title('Distribution of 95th Percentile Gusts')\n",
    "plt.xlabel('99th Percentile Gust (mph)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='vri', data=station_summary_2023_08_02)\n",
    "plt.title('VRI (Risk Classification) Distribution')\n",
    "plt.xlabel('VRI (H = High, M = Medium, L = Low)')\n",
    "plt.ylabel('Count of Stations')\n",
    "plt.show()\n",
    "# plt.close()\n",
    "\n",
    "# Bar plot for Alert Levels\n",
    "sns.countplot(x='alert', data=station_summary_2023_08_02)\n",
    "plt.title('Alert Level Distribution')\n",
    "plt.xlabel('Alert Level')\n",
    "plt.ylabel('Count of Stations')\n",
    "plt.show()\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 Merging datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging the two datasets about weather stations together\n",
    "merged_df = pd.merge(station_summary_2023_08_02, gis_2024_1004, right_on= 'weatherstationcode', left_on='station', how='left')\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\glori\\AppData\\Local\\Temp\\ipykernel_15384\\1844995259.py:8: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  elevation_vri_grouped = merged_df.groupby('elevation_group')['vri'].value_counts().unstack().fillna(0)\n"
     ]
    }
   ],
   "source": [
    "bins = range(0, 5800, 400)  \n",
    "labels = [f'Group{i+1}: {bins[i]}-{bins[i+1]}' for i in range(len(bins)-1)]  # Create group labels\n",
    "\n",
    "# Assign the binned elevation groups\n",
    "merged_df['elevation_group'] = pd.cut(merged_df['elevation'], bins=bins, labels=labels)\n",
    "\n",
    "\n",
    "elevation_vri_grouped = merged_df.groupby('elevation_group')['vri'].value_counts().unstack().fillna(0)\n",
    "elevation_vri_grouped.plot(kind='bar', stacked=True, cmap='viridis')\n",
    "plt.title('VRI (Risk Classification) Across Elevation Groups', fontsize=14)\n",
    "plt.xlabel('Elevation Groups', fontsize=12)\n",
    "plt.ylabel('Number of Stations', fontsize=12)\n",
    "plt.legend(title='VRI Levels', loc='upper right')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vri_weights = {'H': 3, 'M': 2, 'L': 1}\n",
    "merged_df['vri_weight'] = merged_df['vri'].map(vri_weights)\n",
    "\n",
    "# Check for missing values and remove rows with NaN in latitude, longitude, or vri_weight\n",
    "cleaned_df = merged_df.dropna(subset=['latitude', 'longitude', 'vri_weight'])\n",
    "\n",
    "# Create a list of [latitude, longitude, weight] for the heatmap\n",
    "heat_data = [[row['latitude'], row['longitude'], row['vri_weight']] for index, row in cleaned_df.iterrows()]\n",
    "\n",
    "# Create a folium map centered around the average coordinates of the data\n",
    "m = folium.Map(location=[cleaned_df['latitude'].mean(), cleaned_df['longitude'].mean()], zoom_start=10)\n",
    "\n",
    "# Add the heatmap layer\n",
    "HeatMap(heat_data, min_opacity=0.2, radius=20, blur=15, max_zoom=1).add_to(m)\n",
    "\n",
    "# Save the map to an HTML file and display it\n",
    "m.save('geospatial_risk_heatmap.html')\n",
    "\n",
    "# If running in Jupyter or similar environments, you can display the map directly\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Table 3 - Windspeed 2023_08_02\n",
    "#### 1.3.1 Basic Summary Stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "windspeed_2023_08_02_edit = windspeed_2023_08_02.reset_index().drop(columns=['index'])\n",
    "windspeed_2023_08_02_edit['date'] = pd.to_datetime(windspeed_2023_08_02_edit['date'], format='%m/%d/%Y')\n",
    "windspeed_2023_08_02_edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_summary = windspeed_2023_08_02_edit.groupby('station')['wind_speed'].describe()\n",
    "station_summary_edit = station_summary.reset_index()\n",
    "station_summary_edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_wind_speed_merge = pd.merge(station_location, station_summary, left_on='weatherstationcode', right_on='station', how='right')\n",
    "location_wind_speed_merge_edit = location_wind_speed_merge.drop(columns=['weatherstationcode'])\n",
    "location_wind_speed_merge_edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = location_wind_speed_merge_edit.corr()\n",
    "sns.heatmap(matrix, cmap=\"Greens\", annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Seems that there is a correlation between the wind speed and the longitude. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "windspeed_2023_08_02_group = windspeed_2023_08_02.groupby('station')['wind_speed'].mean()\n",
    "windspeed_2023_08_02_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram for wind speed distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(windspeed_2023_08_02_edit['wind_speed'], bins=20, kde=True)\n",
    "plt.title('Distribution of Wind Speeds')\n",
    "plt.xlabel('Wind Speed (mph)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We have an outlier of windspeed over 600mph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "windspeed_2023_08_02[windspeed_2023_08_02['wind_speed'] > 600]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='station', y='wind_speed', data=windspeed_2023_08_02_edit)\n",
    "plt.title('Wind Speed Distribution by Station')\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel('Station')\n",
    "plt.ylabel('Wind Speed (mph)')\n",
    "plt.show()\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.2 Analysis of windspeed over time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "windspeed_2023_08_02_edit['month'] = windspeed_2023_08_02_edit['date'].dt.month\n",
    "\n",
    "month_summary = windspeed_2023_08_02_edit.groupby('month')['wind_speed'].describe()\n",
    "month_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 6))\n",
    "sns.lineplot(x='date', y='wind_speed', data=windspeed_2023_08_02_edit)\n",
    "plt.title('Wind Speed Over Time (All Stations)')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Wind Speed (mph)')\n",
    "plt.show()\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "windspeed_2023_08_02_edit['date'] = pd.to_datetime(windspeed_2023_08_02_edit['date'])\n",
    "\n",
    "# Extract month and year from the date\n",
    "windspeed_2023_08_02_edit['month'] = windspeed_2023_08_02_edit['date'].dt.month\n",
    "windspeed_2023_08_02_edit['year'] = windspeed_2023_08_02_edit['date'].dt.year\n",
    "\n",
    "# Boxplot to show wind speed by month\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(x='month', y='wind_speed', data=windspeed_2023_08_02_edit)\n",
    "plt.title('Wind Speed by Month')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Wind Speed (mph)')\n",
    "plt.show()\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasonal_corr = windspeed_2023_08_02_edit.groupby('month')['wind_speed'].mean()\n",
    "\n",
    "# Plot the average wind speed for each month\n",
    "plt.figure(figsize=(12, 6))\n",
    "seasonal_corr.plot(kind='bar')\n",
    "plt.title('Average Wind Speed by Month')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Average Wind Speed (mph)')\n",
    "plt.show()\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Probability\n",
    "\n",
    "Calculating PSPS Probability for each Weather Station "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not all stations have the same number of windspeed records\n",
    "windspeed_grouped_count = windspeed_2023_08_02.groupby(by='station').count()\n",
    "windspeed_grouped_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_codes = np.array(gis_2024_1004['weatherstationcode'])\n",
    "merged_station_df = gis_2024_1004.merge(station_summary_2023_08_02, left_on='weatherstationcode', right_on='station', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example: showing the windspeed alert threshold for the station \"AMO\"\n",
    "merged_df[merged_df['weatherstationcode']=='AMO']['alert'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\glori\\AppData\\Local\\Temp\\ipykernel_15384\\2284884836.py:12: RuntimeWarning: Mean of empty slice\n",
      "  mean = np.nanmean(station_windspeeds)\n"
     ]
    }
   ],
   "source": [
    "# getting the PSPS probabilities of all weather stations\n",
    "prob_lst = []\n",
    "\n",
    "for station in station_codes:\n",
    "    station_windspeeds = np.array(windspeed_2023_08_02[windspeed_2023_08_02['station'] == station]['wind_speed'])\n",
    "    # \"alert\" might be nan because of less entries in station_ss_df \n",
    "    has_threshold = True\n",
    "    try: \n",
    "        threshold = merged_df[merged_df['weatherstationcode'] == station]['alert'].iloc[0]\n",
    "    except:\n",
    "        has_threshold = False\n",
    "        prob = np.nan\n",
    "    mean = np.nanmean(station_windspeeds)\n",
    "    if has_threshold:\n",
    "        prob = np.mean([1 if x >= threshold else 0 for x in station_windspeeds]) * 100\n",
    "    count = np.count_nonzero(~np.isnan(station_windspeeds))\n",
    "    prob_lst.append([station, station_windspeeds, threshold, count, mean, prob])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# viewing the probabilities as a dataframe\n",
    "prob_df = pd.DataFrame(prob_lst)\n",
    "prob_df.columns = ['station', 'windspeeds', 'threshold', 'count', 'mean', 'probability (%)']\n",
    "prob_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max prob: 85.47486033519553\n",
      "min prob: 0.0\n"
     ]
    }
   ],
   "source": [
    "print('max prob: ' + str(prob_df['probability (%)'].max()))\n",
    "print('min prob: ' + str(prob_df['probability (%)'].min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# station mismatches between table 1 and table 2\n",
    "prob_mismatch = prob_df[prob_df['count'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort probability high to low\n",
    "prob_sorted = prob_df.sort_values(by='probability (%)', ascending=False)[:-5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stations with less than 50 windspeed records\n",
    "prob_less50 = prob_df[prob_df['count'] <50].sort_values(by='count', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist_boxplot(station):\n",
    "    plt.figure(figsize =(4, 4))\n",
    "    subset = np.array(windspeed_2023_08_02[windspeed_2023_08_02['station'] == station]['wind_speed'])\n",
    "    sns.boxplot(subset, width=0.2)\n",
    "    threshold = prob_df[prob_df['station'] == station]['threshold'].iloc[0]\n",
    "    plt.axhline(threshold)\n",
    "    prob = prob_df[prob_df['station'] == station]['probability (%)'].iloc[0]\n",
    "    plt.text(x=0, y=38, s=f'probability: ' + str(prob), color='red')\n",
    "    plt.title(station)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can run a loop to show all stations distribtuion\n",
    "# for station in station_codes:\n",
    "#     dist_boxplot(station)\n",
    "\n",
    "# showing an example for station \"AMO\"\n",
    "dist_boxplot(\"AMO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Geospatial Visualization\n",
    "\n",
    "\n",
    "### 3.1 New datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\glori\\AppData\\Local\\Temp\\ipykernel_15384\\4187153652.py:4: DtypeWarning: Columns (3,4,5,6,8,10,11,12,14,16,17,20,21,22,23,24,25,34,35,36,37,38,42,44,45,65,66,67,68,69,71,72,82,83,84,87,88,91,92,94,100,101) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  wingspan_df = pd.read_csv('data/dev_wings_agg_span_2024_01_01.csv')\n"
     ]
    }
   ],
   "source": [
    "vri_df = pd.read_csv('data/src_vri_snapshot_2024_03_20.csv')\n",
    "wingspan_df = pd.read_csv('data/dev_wings_agg_span_2024_01_01.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vri_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vri_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.1 Changing shape columns to geometry type\n",
    "\n",
    "Currently, the `shape` column datatype is `str` when it should be geometry\n",
    "\n",
    "Also need to reproject to the same `shape_srid` ESPG:4326"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "gis_2024_1004['shape'] = gpd.GeoSeries.from_wkt(gis_2024_1004['shape'])\n",
    "gis_gdf = gpd.GeoDataFrame(gis_2024_1004, geometry='shape').set_crs(epsg=4431).to_crs(epsg=4326)\n",
    "# gis_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "vri_df['shape'] = gpd.GeoSeries.from_wkt(vri_df['shape'])\n",
    "vri_gdf = gpd.GeoDataFrame(vri_df, geometry='shape').set_crs(epsg=4326)\n",
    "# vri_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "wingspan_df['shape'] = gpd.GeoSeries.from_wkt(wingspan_df['shape'])\n",
    "wingspan_gdf = gpd.GeoDataFrame(wingspan_df, geometry='shape').set_crs(epsg=2230).to_crs(epsg=4326)\n",
    "# wingspan_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the shape_srid columns since we have reprojected and they are no longer correct/meaningful \n",
    "gis_gdf = gis_gdf.drop(columns=['shape_srid'])\n",
    "vri_gdf = vri_gdf.drop(columns=['shape_srid'])\n",
    "wingspan_gdf = wingspan_gdf.drop(columns=['shape_srid'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.2 Merging datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge on weather station codes, not yet spatial join using gpd\n",
    "gis_vri_merge = gis_gdf.merge(vri_gdf, left_on='weatherstationcode', right_on='anemometercode')\n",
    "# gis_vri_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\glori\\AppData\\Local\\Temp\\ipykernel_15384\\997739813.py:2: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  vri_gdf['centroid'] = vri_gdf['shape'].centroid\n"
     ]
    }
   ],
   "source": [
    "# find polygon centroids then merge with points\n",
    "vri_gdf['centroid'] = vri_gdf['shape'].centroid\n",
    "# vri_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spatial join\n",
    "vri_gis_sjoin = vri_gdf.sjoin(gis_gdf, how='inner')\n",
    "# vri_gis_sjoin.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Found some anomolies with the dataframe sizes, there seem to be duplicates with the same station name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(223, 26)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gis_gdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(308, 27)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vri_gdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(309, 53)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vri_gis_sjoin.shape\n",
    "# one extra row?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "253"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vri_gis_sjoin.index.nunique()\n",
    "# duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# another spatial join\n",
    "vri_wingspan_sjoin = vri_gdf.sjoin(wingspan_gdf)\n",
    "# vri_wingspan_sjoin.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(255894, 130)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vri_wingspan_sjoin.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(674592, 103)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wingspan_gdf.shape\n",
    "# significantly less rows (intersections)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Visualization with probabilities\n",
    "\n",
    "#### 3.2.1 Folium map with different layers\n",
    "\n",
    "Weather station markers, VRI risks (heatmap), VRI areas (polygons), PSPS probability (heatmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge prob_df with the new spatially joined df\n",
    "prob_merge = vri_gis_sjoin.merge(prob_df, left_on='weatherstationcode', right_on='station').merge(station_summary_2023_08_02, left_on='weatherstationcode', right_on='station')\n",
    "# prob_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "## VRI risk heatmap\n",
    "vri_weights = {'H': 3, 'M': 2, 'L': 1}\n",
    "prob_merge['vri_weight'] = prob_merge['vri'].map(vri_weights)\n",
    "\n",
    "## PSPS probability heatmap \n",
    "# FIXME: heatmap weights not displaying correctly\n",
    "prob_quantiles = prob_merge['probability (%)'].quantile([0.25, 0.5, 0.75]).tolist()\n",
    "prob_weights = []\n",
    "for _, row in prob_merge.iterrows():\n",
    "    w = 0\n",
    "    if row['probability (%)'] < prob_quantiles[0]:\n",
    "        w = 1\n",
    "    elif row['probability (%)'] < prob_quantiles[1]:\n",
    "        w = 2\n",
    "    else:\n",
    "        w = 3\n",
    "    prob_weights.append(w)\n",
    "prob_merge['psps_weight'] = prob_weights\n",
    "\n",
    "# Check for missing values and remove rows with NaN in latitude, longitude, vri_weight, or probability\n",
    "cleaned_df = prob_merge.dropna(subset=['latitude', 'longitude', 'vri_weight', 'psps_weight'])\n",
    "\n",
    "# Create a list of [latitude, longitude, weight] for the heatmap\n",
    "heat_data = [[row['latitude'], row['longitude'], row['vri_weight']] for index, row in cleaned_df.iterrows()]\n",
    "\n",
    "# Create a folium map centered around the average coordinates of the data\n",
    "middle_point = [cleaned_df['latitude'].mean(), cleaned_df['longitude'].mean()]\n",
    "m = folium.Map(location=middle_point, zoom_start=10)\n",
    "\n",
    "# Add the heatmap layers\n",
    "heatmap_layer = folium.FeatureGroup(name='VRI risk')\n",
    "HeatMap(heat_data, min_opacity=0.2, radius=20, blur=15, max_zoom=1, name='VRI risk').add_to(heatmap_layer)\n",
    "heatmap_layer.add_to(m)\n",
    "\n",
    "psps_prob = folium.FeatureGroup(name='PSPS probability')\n",
    "heat_data2 = [[row['latitude'], row['longitude'], row['psps_weight']] for index, row in cleaned_df.iterrows()]\n",
    "HeatMap(heat_data2, min_opacity=0.2, radius=20, blur=15, max_zoom=1, name='PSPS prob').add_to(psps_prob)\n",
    "psps_prob.add_to(m)\n",
    "\n",
    "\n",
    "## Add weather station points to the map\n",
    "marker_group = folium.FeatureGroup(name=\"Weather stations\")\n",
    "for _, row in prob_merge.iterrows():\n",
    "    # Create a popup with relevant information\n",
    "    popup_text = f\"\"\"\n",
    "    Weather Station: {row['weatherstationname']} ({row['weatherstationcode']})<br>\n",
    "    Elevation: {row['elevation']} m<br>\n",
    "    NWS Zone: {row['nwszone']}<br>\n",
    "    PSPS Probability: {row['probability (%)']}<br>\n",
    "    \"\"\"\n",
    "    \n",
    "    # Add a marker for each weather station\n",
    "    folium.Marker(\n",
    "        location=[row['latitude'], row['longitude']],\n",
    "        popup=folium.Popup(popup_text, max_width=300),\n",
    "        icon=folium.Icon(color='blue', icon='info-sign')\n",
    "    ).add_to(marker_group)\n",
    "marker_group.add_to(m)\n",
    "\n",
    "\n",
    "## Add VRI polygons layer\n",
    "vri_polygons = folium.FeatureGroup(name='VRI polygons')\n",
    "for i in vri_gdf['shape']:\n",
    "    folium.GeoJson(i).add_to(vri_polygons)\n",
    "vri_polygons.add_to(m)\n",
    "\n",
    "\n",
    "# Create a layer control object and add it to our map instance\n",
    "folium.LayerControl().add_to(m)\n",
    "\n",
    "# Save the map to an HTML file and display it\n",
    "m.save('layered_map.html')\n",
    "\n",
    "# Display interactive map in Jupyter\n",
    "# m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2 Conductor spans "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wingspan_gdf.groupby(by='psps_station').count()\n",
    "# each psps station has a different number of conductor spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create folium map object\n",
    "conductor_map = folium.Map(location=middle_point)\n",
    "\n",
    "\n",
    "## add weather station points to the map\n",
    "marker_group = folium.FeatureGroup(name=\"Weather stations\")\n",
    "for _, row in gis_gdf.iterrows():\n",
    "    # Create a popup with relevant information\n",
    "    popup_text = f\"\"\"\n",
    "    Weather Station: {row['weatherstationname']}<br>\n",
    "    Structure ID: {row['structureid']}<br>\n",
    "    \"\"\"\n",
    "    \n",
    "    # Add a marker for each weather station\n",
    "    folium.Marker(\n",
    "        location=[row['latitude'], row['longitude']],\n",
    "        popup=folium.Popup(popup_text, max_width=300),\n",
    "        icon=folium.Icon(color='blue', icon='info-sign')\n",
    "    ).add_to(marker_group)\n",
    "marker_group.add_to(conductor_map)\n",
    "\n",
    "\n",
    "# add hlines (each line is blue and very short)\n",
    "line_group = folium.FeatureGroup(name='Conductor spans')\n",
    "# only using the first 1000 lines as examples so the map/file isn't too large\n",
    "for i in wingspan_gdf['shape'][:1000]:\n",
    "    folium.GeoJson(i).add_to(line_group)\n",
    "line_group.add_to(conductor_map)\n",
    "\n",
    "# add lines, grouped by the psps station it is tied to \n",
    "# commented out bc the full map/file becomes too large to be uploaded to github\n",
    "# for group_name, group_data in wingspan_gdf.groupby('psps_station'):\n",
    "#     feature_group = folium.FeatureGroup(name=str(group_name))\n",
    "#     for _, row in group_data.iterrows()[:1000]:\n",
    "#         folium.GeoJson(\n",
    "#             row['shape'],\n",
    "#             name=str(group_name)\n",
    "#         ).add_to(feature_group)\n",
    "#     feature_group.add_to(conductor_map)\n",
    "\n",
    "\n",
    "# add layer (to show the difference of added objects more clearly)\n",
    "folium.LayerControl().add_to(conductor_map)\n",
    "\n",
    "# Save the map to an HTML file and display it\n",
    "conductor_map.save('conductor_span_map.html')\n",
    "\n",
    "# conductor_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Attempted to color each group of conductor spans differently but had some difficulties. The code in the cell below contains errors and is incomplete/does not display correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LINESTRING (-117.2489844152717 33.36251395510124, -117.2490227915011 33.36251409901239, -117.2490305309156 33.36252238895723, -117.2493242214726 33.36252357354851, -117.2493327467301 33.36252254813497, -117.2493410980238 33.3625207778886, -117.2493491826715 33.36251828649861, -117.2493569127012 33.36251509685241, -117.2493642026199 33.36251124986617, -117.2493709724645 33.36250678394365, -117.2493771516099 33.36250174757975, -117.2493826672817 33.36249619747974, -117.2493874634308 33.36249019311119, -117.2493914825912 33.36248380348449, -117.2493946859549 33.36247709262277, -117.2493958060387 33.3624741219845, -117.2494006615879 33.36246553168967, -117.249406563383 33.36245741277092, -117.2494134406315 33.362449858397, -117.2494212247157 33.36244294627029, -117.2494237380283 33.36244083326219, -117.2494313326589 33.36243529432124, -117.249439573983 33.36243045217067, -117.2494483721206 33.36242636103945, -117.2494576326338 33.36242306092624, -117.2494672544047 33.36242059283163, -117.2494771304314 33.36241898182705, -117.2494871526904 33.36241824814133, -117.2496226049828 33.36241690344337, -117.2496310341664 33.3624575477108, -117.249647642828 33.3624573817895)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\glori\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[63], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, row \u001b[38;5;129;01min\u001b[39;00m group_data\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m     19\u001b[0m         \u001b[38;5;28mprint\u001b[39m(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 20\u001b[0m         folium\u001b[38;5;241m.\u001b[39mGeoJson(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m'\u001b[39m], name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(group_name), style_function\u001b[38;5;241m=\u001b[39mstyle_function)\u001b[38;5;241m.\u001b[39madd_to(feature_group)\n\u001b[0;32m     21\u001b[0m     feature_group\u001b[38;5;241m.\u001b[39madd_to(conductor_map)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# add layer control \u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\glori\\anaconda3\\Lib\\site-packages\\folium\\features.py:648\u001b[0m, in \u001b[0;36mGeoJson.__init__\u001b[1;34m(self, data, style_function, highlight_function, name, overlay, control, show, smooth_factor, tooltip, embed, popup, zoom_on_click, marker)\u001b[0m\n\u001b[0;32m    646\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_to_feature_collection()\n\u001b[0;32m    647\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstyle:\n\u001b[1;32m--> 648\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_function(style_function, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstyle_function\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    649\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstyle_function \u001b[38;5;241m=\u001b[39m style_function\n\u001b[0;32m    650\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstyle_map \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[1;32mc:\\Users\\glori\\anaconda3\\Lib\\site-packages\\folium\\features.py:724\u001b[0m, in \u001b[0;36mGeoJson._validate_function\u001b[1;34m(self, func, name)\u001b[0m\n\u001b[0;32m    721\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    723\u001b[0m test_feature \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m--> 724\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(func) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func(test_feature), \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    725\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    726\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m should be a function that accepts items from \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    727\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m] and returns a dictionary.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(name)\n\u001b[0;32m    728\u001b[0m     )\n",
      "Cell \u001b[1;32mIn[63], line 9\u001b[0m, in \u001b[0;36mstyle_function\u001b[1;34m(group_name)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstyle_function\u001b[39m(group_name):\n\u001b[0;32m      8\u001b[0m     group_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(group_name)\n\u001b[1;32m----> 9\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mord\u001b[39m(group_data[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m71\u001b[39m:\n\u001b[0;32m     10\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolor\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124morange\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopacity\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m0.5\u001b[39m}\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mord\u001b[39m(group_data[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m80\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\glori\\anaconda3\\Lib\\site-packages\\geopandas\\geodataframe.py:1474\u001b[0m, in \u001b[0;36mGeoDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1470\u001b[0m \u001b[38;5;124;03m    If the result is a column containing only 'geometry', return a\u001b[39;00m\n\u001b[0;32m   1471\u001b[0m \u001b[38;5;124;03m    GeoSeries. If it's a DataFrame with any columns of GeometryDtype,\u001b[39;00m\n\u001b[0;32m   1472\u001b[0m \u001b[38;5;124;03m    return a GeoDataFrame.\u001b[39;00m\n\u001b[0;32m   1473\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1474\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(key)\n\u001b[0;32m   1475\u001b[0m     \u001b[38;5;66;03m# Custom logic to avoid waiting for pandas GH51895\u001b[39;00m\n\u001b[0;32m   1476\u001b[0m     \u001b[38;5;66;03m# result is not geometry dtype for multi-indexes\u001b[39;00m\n\u001b[0;32m   1477\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   1478\u001b[0m         pd\u001b[38;5;241m.\u001b[39mapi\u001b[38;5;241m.\u001b[39mtypes\u001b[38;5;241m.\u001b[39mis_scalar(key)\n\u001b[0;32m   1479\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m key \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1482\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_geometry_type(result)\n\u001b[0;32m   1483\u001b[0m     ):\n",
      "File \u001b[1;32mc:\\Users\\glori\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\glori\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "# create folium map object\n",
    "conductor_map = folium.Map(location=middle_point)\n",
    "\n",
    "## add lines, grouped by the psps station it is tied to \n",
    "\n",
    "# define a style function for different stations/conductor groups\n",
    "def style_function(group_name):\n",
    "    group_name = str(group_name)\n",
    "    if ord(group_data[0]) < 71:\n",
    "        return {'color': 'orange', 'opacity':0.5}\n",
    "    elif ord(group_data[0]) < 80:\n",
    "        return {'color': 'pink', 'opacity':0.5}\n",
    "    else:\n",
    "        return {'color': 'purple', 'opacity':0.5}\n",
    "    \n",
    "for group_name, group_data in wingspan_gdf.groupby('psps_station'):\n",
    "    feature_group = folium.FeatureGroup(name=str(group_name))\n",
    "    for _, row in group_data.iterrows():\n",
    "        print(row['shape'])\n",
    "        folium.GeoJson(row['shape'], name=str(group_name), style_function=style_function).add_to(feature_group)\n",
    "    feature_group.add_to(conductor_map)\n",
    "\n",
    "# add layer control \n",
    "folium.LayerControl().add_to(conductor_map)\n",
    "\n",
    "# conductor_map"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
